# 3.1 지도학습과 비지도학습

* ✔ **지도학습(supervised learning)**
```
	* 정답을 알려주면서 진행되는 학습
	* 학습 시 데이터와 함께 레이블(정답)이 항상 제공되어야 함
	* 정답 = 실제값 = 레이블 = 타깃 = 클래스 = y값
	* 주로 주어진 데이터와 레이블을 예측해야 할 때 사용됨
	* 머신러닝 모델을 통해 예측된 값 : 예측값 = 분류값 = y hat
	* 예) 분류, 회귀 등
```
* ✔ **비지도학습(unsupervised learning)**
```
	* `레이블(정답)`이 없이 진행되는 학습
	* 주로 데이터 자체에서 패턴을 찾아낼 때 사용됨
	* 예) 군집화, 차원축소
```

# 3.2 분류와 회귀

 데이터가 입력됐을 때 분류는 분리된 값으로 예측하고, 회귀는 연속된 값으로 예측한다.
 예) 날씨 : 분류 - 덥다, 춥다    회귀 - 30.5도, 3.5도

* ✔ **분류(classification)**
	* 데이터가 입력됐을 때 지도학습을 통해 미리 학습된 레이블 중 하나 또는 여러 개의 레이블로 예측하는 것
	* 🗨 **이진분류**
		* (예, 아니오), (남자, 여자)처럼 둘 중 하나의 값으로 분류
	* 🗨 **다중분류**
		* (빨강, 노랑, 파랑), (0,1,2,3,4,5,6,7,8,9)처럼 여러 개 중 하나의 값으로 예측
	* 🗨 **다중 레이블 분류**
		* 데이터가 입력됐을 떄 두 개 이상의 레이블로 분류할 경우

* ✔ **회귀(regression)**
	* 입력된 데이터에 대해 정해진 레이블이 아닌 연속된 값으로 예측


# 3.3 과대적합과 과소적합

 데이터에서 충분히 특징을 찾아내지 못하고 머신러닝 모델을 학습할 겨우 모델이 과속적합되기 쉽고, 필요 이상의 특징으로 학습할 경우 모델이 과대적합되기 쉽다. 과대적합이면 분산(variance)이 높아지고 과소적합이면 편향(bias)이 높아진다. 최적의 모델은 에러율이 가장 적은 모델, 즉 분산과 편향이 균형된 모델이다.

 * ✔ **과소적합(underfitting)**
 	* 모델 학습 시 충분한 데이터의 특징을 활용하지 못할 경우 발생
 	* 충분하지 못한 특징만으로 학습되어 특정 특징에만 편향되게 학습된 모델
 	* 보통 테스트 데이터뿐만 아니라 학습 데이터에 대해서도 정확도가 낮게 나올 경우 과소적합된 모델일 가능성이 높다.

 * ✔ **과대적합(overfitting)**
 	* 학습 데이터에서 필요 이상으로 특징을 발견해서(분산이 높아짐) 학습 데이터에 대한 정확도는 상당히 높지만, 테스트 데이터 또는 학습 데이터 외의 데이터에는 정확도가 낮은 모델
 	* ❓과대적합을 피하기 위해선?
 		* 더 많은 데이터를 확보해서 부족한 학습 데이터 충분히 채우기
 		* 학습에 사용된 특징을 줄여보기
 		* 특징들의 수치값을 정규화함으로써 특정 특징에 의한 편향 줄이기
 		* 딥러닝 - 조기 종료(early stopping), 드롭아웃(drop out)


# 3.4 혼동행렬(confusion matrix)

* 모델의 성능을 평가할 떄 사용되는 지표
* 모델이 어떤 것과 다른 어떤 것을 혼동하는지를 알아내 개선할 수 있음
* 모델의 성능은 바로 이 혼동행렬을 기반으로 단 하나의 수치로 표현함

# 3.5 머신러닝 모델의 성능 평가

1️⃣ `TP(true positive)` - 맞는 것을 올바르게 예측한 것 (A를 A라고 예측)

2️⃣ `TN(true negative)` - 틀린 것을 올바르게 예측한   (A가 아닌 것을 A가 아니라고 예측)

3️⃣ `FP(false positive)` - 틀린 것을 맞다고 잘못 예측한 것 (A가 아닌 거을 A라고 예측)

4️⃣ `FN(flase negative)` - 맞는 것을 틀렸다고 잘못 예측한 것 (A를 A가 아니라고 예측)

* ✔ **정확도(Accuracy)**
	* 모델이 입력된 데이터에 대해 얼마나 정확하게 예측하는가
	* **정확도 = TP의 합 / 전체 값**

* ✔ **정밀도(precision)**
	* 모델의 예측값이 얼마나 정확하게 예측됐는가
	* 대표적 예 : 병원에서 암을 진찰하는 기계
	* **정밀도 = TP / (TP + FP)**

* ✔ **재현율(Recall)**
	* 실제값 중에서 모델이 검출한 실제값의 비율
	* **재현율 = TP / (TP + FN)**
	* 예 : 실제 암환자들이 암환자라고 예측될 확률

* ✔ **F1 점수(F1 score)**
	* 정밀도와 재현율을 조화평균 내서 하나의 수치로 나타낸 지표
	* 조화평균 = 2 * a * b / (a + b)
	* **F1 점수 = 2 * 재현율 * 정밀도 / (재현율 + 정밀도)**

* 🔸 **정확도 vs F1 점수** 🔸
	* 정확도 - 테스트 데이터의 레이블이 균일하게 분포돼 있을 때
	* F1 점수 - 테스트 데이터의 레이블이 불균일하게 분포돼 있을 때

# 3.6 k-폴드 교차 검증

 머신러닝 모델 테스트 전에 검증 단게를 통해 대략적인 모델 성능을 짐작할 수 있다. 
 보통 하나의 데이터셋이 있으면 전체 데이터셋의 20%를 테스트 데이터로, 나머지(80%)의 90%를 학습 데이터로, 10%를 검증 데이터로 많이 사용한다.
 하지만 데이터가 충분하지 않은 경우 10%를 검증 데이터로 나누기도 아깝고, 나눈다 해도 검증 정확도를 신뢰하기에 너무 한쪽에 편중된다는 단점이 있다.
 이를 극복한 것이 k-폴드(k-fold) 교차 검증이다. 

 * 테스트 데이터와 학습 데이터로 나누고 학습 데이터의 일정 부분을 검증 데이터로 쓰되, n번의 검증 과정을 통해 학습 데이터의 모든 데이터를 한 번씩 검증 데이터로 사용해 n개의 검증 결과를 평균낸 값을 검증 성능 평가 지표로 사용하는 방식
 * 장점
 	1. 검증 결과가 일정 데이터에 치우치지 않고 모든 데이터에 대한 결과이므로 신빙성이 높다.
 	2. 따로 검증 데이터를 분리하지 않아도 된다.

 